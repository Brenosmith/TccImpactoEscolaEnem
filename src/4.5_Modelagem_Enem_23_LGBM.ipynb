{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d08606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV  # Bayesian optimization: utilizado para optimizar hiperpar√°metros\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping  # Early stopping: utilizado para evitar sobreajuste\n",
    "\n",
    "from Funcoes_Comuns import avaliar_modelo, registrar_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5585f",
   "metadata": {},
   "source": [
    "### 1. Recuperar base j√° pr√©-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3aab349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter dados\n",
    "df_enem = pd.read_pickle('Bases\\\\Finais\\\\enem_microdados_2023.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad41c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_alvo = ['NUM_NOTA_MT', 'NUM_NOTA_LC', 'NUM_NOTA_CN', 'NUM_NOTA_CH', 'NUM_NOTA_REDACAO']\n",
    "grupo_previsao = ['NUM_NOTA_CH']\n",
    "\n",
    "# separar em treino e teste\n",
    "X = df_enem.drop(columns=variaveis_alvo)\n",
    "y = df_enem[grupo_previsao]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste de tipo para MLflow\n",
    "# Converter colunas inteiras para float\n",
    "X_train = X_train.astype({col: 'float' for col in X_train.select_dtypes('int').columns})\n",
    "X_test = X_test.astype({col: 'float' for col in X_test.select_dtypes('int').columns})\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Criar Eval Set para valida√ß√£o cruzada (15% do conjunto de treino)\n",
    "X_train_final, X_eval, y_train_final, y_eval = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e26c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar as dimens√µes dos arrays\n",
    "y_test = y_test.squeeze()\n",
    "y_train_final = y_train_final.squeeze()\n",
    "y_eval = y_eval.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adacb19",
   "metadata": {},
   "source": [
    "### 2. Modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be32573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 4296\n",
      "[LightGBM] [Info] Number of data points in the train set: 487214, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 527.881246\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo LGBMRegressor Base\n",
    "modelo_lgbm = lgbm.LGBMRegressor(n_estimators=1000, \n",
    "                                 learning_rate=0.01, \n",
    "                                 random_state=42,\n",
    "                                 max_bin=4095,\n",
    "                                 force_row_wise=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "modelo_lgbm.fit(X_train_final, \n",
    "                y_train_final, \n",
    "                eval_set=[(X_eval, y_eval)], \n",
    "                eval_metric=['r2', 'rmse', 'mae'],\n",
    "                categorical_feature=categorical_features)\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f9a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_base = modelo_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186e0b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run orderly-squid-275 at: http://127.0.0.1:9080/#/experiments/957135083854196683/runs/103d90b76ba64bdc8057aa6044df760d\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/957135083854196683\n",
      "Erro ao registrar o modelo no MLflow: 'NUM_NOTA_CH'\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Notas CH ENEM 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                    parametros={**modelo_lgbm.get_params(), \"amostra\": X_train_final.shape[0], \"tempo\": tempo_treino},\n",
    "                    X_train=X_train_final,\n",
    "                    y_train=y_train_final,\n",
    "                    y_test=y_test,\n",
    "                    y_pred=y_pred_base,\n",
    "                    variavel_alvo='NUM_NOTA_CH',\n",
    "                    modelo=modelo_lgbm,\n",
    "                    nome_modelo='modelo_lgbm_base',\n",
    "                    descricao_modelo='Modelo LGBMRegressor base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8846746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 53.5294\n",
      "RMSE (treino): 67.8961\n",
      "R2 (treino): 0.3564\n",
      "MAE (teste): 55.2285\n",
      "RMSE (teste): 70.0224\n",
      "R2 (teste): 0.3122\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train_final, modelo_lgbm.predict(X_train_final), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test, y_pred_base, \"teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75b3412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modelos\\\\modelo_lgbm_base.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar o modelo otimizado como um arquivo pickle\n",
    "joblib.dump(modelo_lgbm, 'Modelos\\\\modelo_lgbm_base.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4743201",
   "metadata": {},
   "source": [
    "### 3. Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a727da",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lgbm_bayes = lgbm.LGBMRegressor(random_state=42,\n",
    "                                       max_bin=4095, \n",
    "                                       force_row_wise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8412f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o do espa√ßo de busca para otimiza√ß√£o bayesiana\n",
    "param_grid = {\n",
    "    'num_leaves': (52, 60),                         # N√∫mero de folhas na √°rvore de decis√£o\n",
    "    'max_depth': (60, 100),                         # Profundidade m√°xima da √°rvore\n",
    "    'learning_rate': (0.001, 0.01, 'log-uniform'),  # Taxa de aprendizado\n",
    "    'n_estimators': (5000, 6000),                   # N√∫mero de √°rvores\n",
    "    'subsample': (0.5, 0.9),                        # Propor√ß√£o de amostras usadas em cada √°rvore\n",
    "    'colsample_bytree': (0.3, 0.9),                 # Fra√ß√£o de colunas a serem usadas por √°rvore\n",
    "    'reg_alpha': (1e-3, 1e-1, 'log-uniform'),       # Regulariza√ß√£o L1\n",
    "    'reg_lambda': (1e-6, 1e-4, 'log-uniform'),      # Regulariza√ß√£o L2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16ccdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar a busca Bayesiana usando BayesSearchCV\n",
    "\n",
    "# Criando o otimizador Bayesiano\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=modelo_lgbm_bayes,    # Modelo a ser otimizado\n",
    "    search_spaces=param_grid,       # Espa√ßo de busca definido acima\n",
    "    scoring='r2',                   # Crit√©rio de sele√ß√£o\n",
    "    n_iter=20,                      # N√∫mero de avalia√ß√µes do modelo\n",
    "    cv=3,                           # Valida√ß√£o cruzada\n",
    "    random_state=42,                # Semente para reprodutibilidade\n",
    "    n_jobs=-1,                      # Paraleliza√ß√£o total dos c√°lculos\n",
    "    verbose=1                       # 0 = sem mensagens, 1 = mensagens de progresso, 2 = mensagens detalhadas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7078d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': ['r2', 'rmse', 'mae'],               # M√©tricas a serem avaliadas\n",
    "    'categorical_feature': categorical_features,        # Colunas categ√≥ricas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63fb8325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Info] Total Bins 4296\n",
      "[LightGBM] [Info] Number of data points in the train set: 487214, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 527.881246\n"
     ]
    }
   ],
   "source": [
    "# Executar a busca Bayesiana\n",
    "\n",
    "start_time = time.time()\n",
    "bayes_search.fit(X_train_final, y_train_final, **fit_params)\n",
    "\n",
    "# Parar o cron√¥metro\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56395a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros: OrderedDict([('colsample_bytree', 0.30911765737060976), ('learning_rate', 0.009989721326532239), ('max_depth', 96), ('n_estimators', 5166), ('num_leaves', 54), ('reg_alpha', 0.04022442508037429), ('reg_lambda', 6.983061213998744e-05), ('subsample', 0.769767140418842)])\n",
      "R2:  0.3170481368467291\n",
      "Tempo total de execu√ß√£o: 25934.18 segundos\n"
     ]
    }
   ],
   "source": [
    "# Melhores par√¢metros encontrados\n",
    "try:\n",
    "    melhores_parametros = bayes_search.best_params_\n",
    "    print(f\"Melhores par√¢metros: {melhores_parametros}\")\n",
    "    print(\"R2: \", bayes_search.best_score_)\n",
    "    print(f\"Tempo total de execu√ß√£o: {elapsed_time:.2f} segundos\")\n",
    "except:\n",
    "    melhores_parametros = {\n",
    "        \"colsample_bytree\": 0.2297823151086026,\n",
    "        \"learning_rate\": 0.028382425255806625,\n",
    "        \"max_depth\": 40,\n",
    "        \"n_estimators\": 5990,\n",
    "        \"num_leaves\": 40,\n",
    "        \"reg_alpha\": 0.00596084139054512,\n",
    "        \"reg_lambda\": 0.8601375912019539,\n",
    "        \"subsample\": 0.9434176158805601\n",
    "    }\n",
    "    print(f\"Erro ao obter melhores par√¢metros, usando valores calculados anteriormente:\\n {melhores_parametros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72438c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 4296\n",
      "[LightGBM] [Info] Number of data points in the train set: 487214, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 527.881246\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4690]\tvalid_0's rmse: 69.8631\tvalid_0's l1: 55.0932\tvalid_0's l2: 4880.86\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.set_params(**melhores_parametros)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Treinamento do modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.fit(X_train_final,\n",
    "                      y_train_final,\n",
    "                      eval_set=[(X_eval, y_eval)], \n",
    "                      eval_metric=['r2', 'rmse', 'mae'],\n",
    "                      categorical_feature=categorical_features,\n",
    "                      callbacks=[early_stopping(stopping_rounds=200)])\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ed2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_bayes = modelo_lgbm_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e84c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run flawless-deer-773 at: http://127.0.0.1:9080/#/experiments/957135083854196683/runs/dae7b788b08842a6b8a9965277dd1b45\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/957135083854196683\n",
      "Erro ao registrar o modelo no MLflow: 'NUM_NOTA_CH'\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Notas CH ENEM 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                    modelo=modelo_lgbm_bayes,\n",
    "                    parametros={**modelo_lgbm_bayes.get_params(), \"amostra\": X_train_final.shape[0], \"tempo\": tempo_treino},\n",
    "                    X_train=X_train_final,\n",
    "                    y_train=y_train_final,\n",
    "                    y_test=y_test,\n",
    "                    y_pred=y_pred_bayes,\n",
    "                    variavel_alvo='NUM_NOTA_CH',\n",
    "                    nome_modelo='modelo_lgbm_bayes',\n",
    "                    descricao_modelo='Modelo LGBMRegressor otimizado com BayesSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1c47eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 52.7391\n",
      "RMSE (treino): 66.9660\n",
      "R2 (treino): 0.3739\n",
      "MAE (teste): 54.8517\n",
      "RMSE (teste): 69.6036\n",
      "R2 (teste): 0.3204\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train_final, modelo_lgbm_bayes.predict(X_train_final), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test, y_pred_bayes, \"teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20721a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modelos\\\\modelo_lgbm_bayes.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar o modelo otimizado como um arquivo pickle\n",
    "joblib.dump(modelo_lgbm_bayes, 'Modelos\\\\modelo_lgbm_bayes.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
