{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08652991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV  # Bayesian optimization: utilizado para optimizar hiperpar√°metros\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping  # Early stopping: utilizado para evitar sobreajuste\n",
    "\n",
    "from Funcoes_Comuns import avaliar_modelo, registrar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10e0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter dados\n",
    "df_enem = pd.read_pickle('Bases\\Finais\\enem_censo_2023_full.pkl')\n",
    "\n",
    "# Remover linhas com valores n√£o explicativos\n",
    "df_enem = df_enem[\n",
    "    (df_enem['CAT_NACIONALIDADE'] != 0) &\n",
    "    (df_enem['CAT_ENSINO'] != 0) &\n",
    "    (df_enem['CAT_COR_RACA'] != 0) &\n",
    "    (df_enem['CAT_ESTADO_CIVIL'] != 0) &\n",
    "    (df_enem['CAT_ESCOLA'] != 1)\n",
    "]\n",
    "\n",
    "#Variaveis alvo\n",
    "variaveis_alvo = ['NUM_NOTA_MT', 'NUM_NOTA_LC', 'NUM_NOTA_CN', 'NUM_NOTA_CH', 'NUM_NOTA_REDACAO']\n",
    "\n",
    "# separar em treino e teste\n",
    "X = df_enem.drop(columns=variaveis_alvo)\n",
    "y = df_enem[variaveis_alvo]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste de tipo para MLflow -> Converter colunas inteiras para float\n",
    "X_train = X_train.astype({col: 'float' for col in X_train.select_dtypes('int').columns})\n",
    "X_test = X_test.astype({col: 'float' for col in X_test.select_dtypes('int').columns})\n",
    "\n",
    "# Obter colunas categ√≥ricas\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Criar Eval Set para valida√ß√£o cruzada (15% do conjunto de treino)\n",
    "# Apenas utilizado nos modelos fianais, BayesSearchCV n√£o utiliza Eval Set j√° possui validacao cruzada interna\n",
    "X_train_final, X_eval, y_train_final, y_eval = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682f9e5",
   "metadata": {},
   "source": [
    "Modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edffdbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30554\n",
      "[LightGBM] [Info] Number of data points in the train set: 457203, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 529.413394\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo LGBMRegressor Base\n",
    "modelo_lgbm = lgbm.LGBMRegressor(n_estimators=1000, \n",
    "                                 learning_rate=0.01, \n",
    "                                 random_state=42,\n",
    "                                 max_bin=4095,\n",
    "                                 force_row_wise=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "modelo_lgbm.fit(X_train_final, \n",
    "                y_train_final['NUM_NOTA_CH'], \n",
    "                eval_set=[(X_test, y_test['NUM_NOTA_CH'])], \n",
    "                eval_metric=['r2', 'rmse', 'mae'],\n",
    "                categorical_feature=categorical_features)\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855be84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred = modelo_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f05a3157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 23:04:43 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Registered model 'modelo_lgbm_base_censo_enem' already exists. Creating a new version of this model...\n",
      "2025/06/07 23:04:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_base_censo_enem, version 3\n",
      "Created version '3' of model 'modelo_lgbm_base_censo_enem'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run casual-chimp-902 at: http://127.0.0.1:9080/#/experiments/957135083854196683/runs/a0aab72192394e7198b77c23dd25713a\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/957135083854196683\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_base_censo_enem\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Notas CH ENEM 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                 parametros={**modelo_lgbm.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                 X_train=X_train,\n",
    "                 y_train=y_train,\n",
    "                 y_test=y_test,\n",
    "                 y_pred=y_pred,\n",
    "                 variavel_alvo='NUM_NOTA_CH',\n",
    "                 modelo=modelo_lgbm,\n",
    "                 nome_modelo='modelo_lgbm_base_censo_enem',\n",
    "                 descricao_modelo='Modelo LGBMRegressor base Censo e ENEM 2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680b8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 53.6244\n",
      "RMSE (treino): 68.0627\n",
      "R2 (treino): 0.3488\n",
      "MAE (teste): 54.9950\n",
      "RMSE (teste): 69.8897\n",
      "R2 (teste): 0.3151\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred, \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20970e9",
   "metadata": {},
   "source": [
    "Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52948cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lgbm_bayes = lgbm.LGBMRegressor(random_state=42,\n",
    "                                       max_bin=4095, \n",
    "                                       force_row_wise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0f50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o do espa√ßo de busca para otimiza√ß√£o bayesiana\n",
    "param_grid = {\n",
    "    'num_leaves': (15, 75),                         # N√∫mero de folhas na √°rvore de decis√£o\n",
    "    'max_depth': (40, 120),                        # Profundidade m√°xima da √°rvore\n",
    "    'learning_rate': (0.005, 0.05, 'log-uniform'), # Taxa de aprendizado\n",
    "    'n_estimators': (5200, 6500),                  # N√∫mero de √°rvores\n",
    "    'subsample': (0.1, 0.9),                       # Propor√ß√£o de amostras usadas em cada √°rvore\n",
    "    'colsample_bytree': (0.1, 0.5),                # Fra√ß√£o de colunas a serem usadas por √°rvore\n",
    "    'reg_alpha': (1e-4, 0.5, 'log-uniform'),       # Regulariza√ß√£o L1\n",
    "    'reg_lambda': (5e-7, 5e-4, 'log-uniform'),     # Regulariza√ß√£o L2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a9c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar a busca Bayesiana usando BayesSearchCV\n",
    "\n",
    "# Criando o otimizador Bayesiano\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=modelo_lgbm_bayes,    # Modelo a ser otimizado\n",
    "    search_spaces=param_grid,       # Espa√ßo de busca definido acima\n",
    "    scoring='r2',                   # Crit√©rio de sele√ß√£o\n",
    "    n_iter=5,                       # N√∫mero de avalia√ß√µes do modelo\n",
    "    cv=3,                           # Valida√ß√£o cruzada\n",
    "    random_state=42,                # Semente para reprodutibilidade\n",
    "    n_jobs=-1,                      # Paraleliza√ß√£o total dos c√°lculos\n",
    "    verbose=1                       # 0 = sem mensagens, 1 = mensagens de progresso, 2 = mensagens detalhadas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c59f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': ['r2'],  #, 'rmse', 'mae'],         # M√©tricas a serem avaliadas\n",
    "    'categorical_feature': categorical_features,       # Colunas categ√≥ricas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b05618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostrar 30% do conjunto de treino para acelerar a busca bayesiana\n",
    "X_bayes, _, y_bayes, _ = train_test_split(X_train, y_train, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e886a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Info] Total Bins 29925\n",
      "[LightGBM] [Info] Number of data points in the train set: 161366, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 529.385178\n"
     ]
    }
   ],
   "source": [
    "# Executar a busca Bayesiana\n",
    "\n",
    "start_time = time.time()\n",
    "# bayes_search.fit(X_train, y_train['NUM_NOTA_CH'], **fit_params)\n",
    "bayes_search.fit(X_bayes, y_bayes['NUM_NOTA_CH'], **fit_params)\n",
    "\n",
    "# Parar o cron√¥metro\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20649f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros: OrderedDict([('colsample_bytree', 0.4249583953429453), ('learning_rate', 0.007427481277233235), ('max_depth', 88), ('n_estimators', 6244), ('num_leaves', 46), ('reg_alpha', 0.00022546821511393962), ('reg_lambda', 9.254897279094798e-05), ('subsample', 0.7981042826479537)])\n",
      "R2:  0.29516189309611746\n",
      "Tempo total de execu√ß√£o: 2582.60 segundos\n"
     ]
    }
   ],
   "source": [
    "# Melhores par√¢metros encontrados\n",
    "try:\n",
    "    melhores_parametros = bayes_search.best_params_\n",
    "    print(f\"Melhores par√¢metros: {melhores_parametros}\")\n",
    "    print(\"R2: \", bayes_search.best_score_)\n",
    "    print(f\"Tempo total de execu√ß√£o: {elapsed_time:.2f} segundos\")\n",
    "except:\n",
    "    melhores_parametros = {'colsample_bytree': 0.4558660098409215, 'learning_rate': 0.008293207307063736, 'max_depth': 66, 'n_estimators': 6300, 'num_leaves': 15, 'reg_alpha': 0.02296127666011783, 'reg_lambda': 5.987427535052461e-07, 'subsample': 0.7012420250723972}\n",
    "    print(f\"Erro ao obter melhores par√¢metros, usando valores calculados anteriormente:\\n {melhores_parametros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce45e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30554\n",
      "[LightGBM] [Info] Number of data points in the train set: 457203, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 529.413394\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1949]\tvalid_0's rmse: 69.8759\tvalid_0's l1: 55.0321\tvalid_0's l2: 4882.64\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.set_params(**melhores_parametros)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Treinamento do modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.fit(X_train_final, \n",
    "                      y_train_final['NUM_NOTA_CH'], \n",
    "                      eval_set=[(X_eval, y_eval['NUM_NOTA_CH'])], \n",
    "                      eval_metric=['r2', 'rmse', 'mae'],\n",
    "                      categorical_feature=categorical_features,\n",
    "                      callbacks=[early_stopping(stopping_rounds=200)])\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52e8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_bayes = modelo_lgbm_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882b3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 00:03:24 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Registered model 'modelo_lgbm_bayes_censo_enem' already exists. Creating a new version of this model...\n",
      "2025/06/12 00:04:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_bayes_censo_enem, version 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run nebulous-donkey-363 at: http://127.0.0.1:9080/#/experiments/957135083854196683/runs/84a7c6a3cd14474db3ec1cdff9c47840\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/957135083854196683\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_bayes_censo_enem\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '6' of model 'modelo_lgbm_bayes_censo_enem'.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Notas CH ENEM 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                    modelo=modelo_lgbm_bayes,\n",
    "                    parametros={**modelo_lgbm_bayes.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    y_test=y_test,\n",
    "                    y_pred=y_pred_bayes,\n",
    "                    variavel_alvo='NUM_NOTA_CH',\n",
    "                    nome_modelo='modelo_lgbm_bayes_censo_enem',\n",
    "                    descricao_modelo='Modelo LGBMRegressor otimizado com BayesSearchCV Censo e ENEM 2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67d1da22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 53.1981\n",
      "RMSE (treino): 67.5621\n",
      "R2 (treino): 0.3583\n",
      "MAE (teste): 54.7792\n",
      "RMSE (teste): 69.6550\n",
      "R2 (teste): 0.3197\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm_bayes.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred_bayes, \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487ed25",
   "metadata": {},
   "source": [
    "testar mais melhoria com base reduzida no bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa412b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/modelo_lgbm_bayes_censo_enem.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar modelo como Pickle\n",
    "joblib.dump(modelo_lgbm_bayes, 'modelos/modelo_lgbm_bayes_censo_enem.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
