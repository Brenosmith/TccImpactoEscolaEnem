{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003fcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV  # Bayesian optimization: utilizado para optimizar hiperpar√°metros\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping  # Early stopping: utilizado para evitar sobreajuste\n",
    "\n",
    "from Funcoes_Comuns import avaliar_modelo, registrar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac66ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter dados socioecon√¥micos e notas do ENEM 2023\n",
    "df_enem = pd.read_pickle('Bases\\Finais\\dados_escolares_2023.pkl')\n",
    "\n",
    "#Variaveis alvo\n",
    "variaveis_alvo = ['NUM_NOTA_MT', 'NUM_NOTA_LC', 'NUM_NOTA_CN', 'NUM_NOTA_CH', 'NUM_NOTA_REDACAO']\n",
    "\n",
    "# separar em treino e teste\n",
    "X = df_enem.drop(columns=variaveis_alvo)\n",
    "y = df_enem[variaveis_alvo]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste de tipo para MLflow -> Converter colunas inteiras para float\n",
    "X_train = X_train.astype({col: 'float' for col in X_train.select_dtypes('int').columns})\n",
    "X_test = X_test.astype({col: 'float' for col in X_test.select_dtypes('int').columns})\n",
    "\n",
    "# Obter colunas categ√≥ricas\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Criar Eval Set para valida√ß√£o cruzada (15% do conjunto de treino)\n",
    "# Apenas utilizado nos modelos fianais, BayesSearchCV n√£o utiliza Eval Set j√° possui validacao cruzada interna\n",
    "X_train_final, X_eval, y_train_final, y_eval = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52d014",
   "metadata": {},
   "source": [
    "Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95c695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30558\n",
      "[LightGBM] [Info] Number of data points in the train set: 487214, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 527.881246\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo LGBMRegressor Base\n",
    "modelo_lgbm = lgbm.LGBMRegressor(n_estimators=1000, \n",
    "                                 learning_rate=0.01, \n",
    "                                 random_state=42,\n",
    "                                 max_bin=4095,\n",
    "                                 force_row_wise=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "modelo_lgbm.fit(X_train_final, \n",
    "                y_train_final['NUM_NOTA_CH'], \n",
    "                eval_set=[(X_test, y_test['NUM_NOTA_CH'])], \n",
    "                eval_metric=['r2', 'rmse', 'mae'],\n",
    "                categorical_feature=categorical_features)\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20fbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred = modelo_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316e6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 16:05:39 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Registered model 'modelo_lgbm_base_escolares_2023' already exists. Creating a new version of this model...\n",
      "2025/06/14 16:06:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_base_escolares_2023, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run enthused-wren-189 at: http://127.0.0.1:9080/#/experiments/623589849857672017/runs/c536e0c351a946f882e640df95bb8dcc\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/623589849857672017\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_base_escolares_2023\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'modelo_lgbm_base_escolares_2023'.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Escolares CH 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                 parametros={**modelo_lgbm.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                 X_train=X_train,\n",
    "                 y_train=y_train,\n",
    "                 y_test=y_test,\n",
    "                 y_pred=y_pred,\n",
    "                 variavel_alvo='NUM_NOTA_CH',\n",
    "                 modelo=modelo_lgbm,\n",
    "                 nome_modelo='modelo_lgbm_base_escolares_2023',\n",
    "                 descricao_modelo='Modelo LGBMRegressor base para dados escolares CH',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c6f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 58.3995\n",
      "RMSE (treino): 73.5504\n",
      "R2 (treino): 0.2452\n",
      "MAE (teste): 58.7444\n",
      "RMSE (teste): 73.9965\n",
      "R2 (teste): 0.2319\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred, \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e27b4",
   "metadata": {},
   "source": [
    "Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e476ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lgbm_bayes = lgbm.LGBMRegressor(random_state=42,\n",
    "                                       max_bin=4095, \n",
    "                                       force_row_wise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d89975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o do espa√ßo de busca para otimiza√ß√£o bayesiana\n",
    "param_grid = {\n",
    "    'num_leaves': (5, 60),                         # N√∫mero de folhas na √°rvore de decis√£o\n",
    "    'max_depth': (60, 120),                        # Profundidade m√°xima da √°rvore\n",
    "    'learning_rate': (0.001, 0.01, 'log-uniform'), # Taxa de aprendizado\n",
    "    'n_estimators': (5000, 8000),                  # N√∫mero de √°rvores\n",
    "    'subsample': (0.1, 0.9),                       # Propor√ß√£o de amostras usadas em cada √°rvore\n",
    "    'colsample_bytree': (0.1, 0.9),                # Fra√ß√£o de colunas a serem usadas por √°rvore\n",
    "    'reg_alpha': (1e-3, 1.0, 'log-uniform'),       # Regulariza√ß√£o L1\n",
    "    'reg_lambda': (1e-7, 1e-2, 'log-uniform'),     # Regulariza√ß√£o L2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82d1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar a busca Bayesiana usando BayesSearchCV\n",
    "\n",
    "# Criando o otimizador Bayesiano\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=modelo_lgbm_bayes,    # Modelo a ser otimizado\n",
    "    search_spaces=param_grid,       # Espa√ßo de busca definido acima\n",
    "    scoring='r2',                   # Crit√©rio de sele√ß√£o\n",
    "    n_iter=15,                       # N√∫mero de avalia√ß√µes do modelo\n",
    "    cv=3,                           # Valida√ß√£o cruzada\n",
    "    random_state=42,                # Semente para reprodutibilidade\n",
    "    n_jobs=-1,                      # Paraleliza√ß√£o total dos c√°lculos\n",
    "    verbose=1                       # 0 = sem mensagens, 1 = mensagens de progresso, 2 = mensagens detalhadas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58217271",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': ['r2', 'rmse', 'mae'],              # M√©tricas a serem avaliadas\n",
    "    'categorical_feature': categorical_features,       # Colunas categ√≥ricas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d2c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Info] Total Bins 30571\n",
      "[LightGBM] [Info] Number of data points in the train set: 573194, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 527.941622\n"
     ]
    }
   ],
   "source": [
    "# Executar a busca Bayesiana\n",
    "\n",
    "start_time = time.time()\n",
    "bayes_search.fit(X_train, y_train['NUM_NOTA_CH'], **fit_params)\n",
    "\n",
    "# Parar o cron√¥metro\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20062d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros: OrderedDict([('colsample_bytree', 0.10290424580379459), ('learning_rate', 0.006574004842664949), ('max_depth', 104), ('n_estimators', 5764), ('num_leaves', 37), ('reg_alpha', 0.006670287398683358), ('reg_lambda', 3.666034360775116e-06), ('subsample', 0.22207566947075547)])\n",
      "R2:  0.23125435204384517\n",
      "Tempo total de execu√ß√£o: 81713.31 segundos\n"
     ]
    }
   ],
   "source": [
    "# Melhores par√¢metros encontrados\n",
    "try:\n",
    "    melhores_parametros = bayes_search.best_params_\n",
    "    print(f\"Melhores par√¢metros: {melhores_parametros}\")\n",
    "    print(\"R2: \", bayes_search.best_score_)\n",
    "    print(f\"Tempo total de execu√ß√£o: {elapsed_time:.2f} segundos\")\n",
    "except:\n",
    "    melhores_parametros = {\n",
    "        'colsample_bytree': 0.10290424580379459, \n",
    "        'learning_rate': 0.006574004842664949, \n",
    "        'max_depth': 104, \n",
    "        'n_estimators': 5764, \n",
    "        'num_leaves': 37, \n",
    "        'reg_alpha': 0.006670287398683358, \n",
    "        'reg_lambda': 3.666034360775116e-06, \n",
    "        'subsample': 0.22207566947075547}\n",
    "    print(f\"Erro ao obter melhores par√¢metros, usando valores calculados anteriormente:\\n {melhores_parametros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18551012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30558\n",
      "[LightGBM] [Info] Number of data points in the train set: 487214, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 527.881246\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4112]\tvalid_0's rmse: 74.1439\tvalid_0's l1: 58.9635\tvalid_0's l2: 5497.32\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.set_params(**melhores_parametros)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Treinamento do modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.fit(X_train_final, \n",
    "                      y_train_final['NUM_NOTA_CH'], \n",
    "                      eval_set=[(X_eval, y_eval['NUM_NOTA_CH'])], \n",
    "                      eval_metric=['r2', 'rmse', 'mae'],\n",
    "                      categorical_feature=categorical_features,\n",
    "                      callbacks=[early_stopping(stopping_rounds=200)])\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1b52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_bayes = modelo_lgbm_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9da75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/15 16:09:17 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Registered model 'modelo_lgbm_bayes_escolares_2023' already exists. Creating a new version of this model...\n",
      "2025/06/15 16:09:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_bayes_escolares_2023, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run calm-grouse-516 at: http://127.0.0.1:9080/#/experiments/623589849857672017/runs/ab5112de34da4dbdbdf6685b08fe8163\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/623589849857672017\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_bayes_escolares_2023\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'modelo_lgbm_bayes_escolares_2023'.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Escolares CH 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                    modelo=modelo_lgbm_bayes,\n",
    "                    parametros={**modelo_lgbm_bayes.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    y_test=y_test,\n",
    "                    y_pred=y_pred_bayes,\n",
    "                    variavel_alvo='NUM_NOTA_CH',\n",
    "                    nome_modelo='modelo_lgbm_bayes_escolares_2023',\n",
    "                    descricao_modelo='Modelo LGBMRegressor otimizado com BayesSearchCV para dados escolares CH',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5d1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 58.4673\n",
      "RMSE (treino): 73.6203\n",
      "R2 (treino): 0.2438\n",
      "MAE (teste): 58.6958\n",
      "RMSE (teste): 73.9089\n",
      "R2 (teste): 0.2338\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm_bayes.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred_bayes, \"teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9600a984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/modelo_lgbm_bayes_escolares.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar modelo como Pickle\n",
    "joblib.dump(modelo_lgbm_bayes, 'modelos/modelo_lgbm_bayes_escolares.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
