{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003fcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV  # Bayesian optimization: utilizado para optimizar hiperpar√°metros\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping  # Early stopping: utilizado para evitar sobreajuste\n",
    "\n",
    "from Funcoes_Comuns import avaliar_modelo, registrar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac66ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter dados socioecon√¥micos e notas do ENEM 2023\n",
    "df_enem = pd.read_pickle('Bases\\Finais\\dados_escolares_2023.pkl')\n",
    "\n",
    "# Remover linhas com valores n√£o explicativos\n",
    "df_enem = df_enem[\n",
    "    (df_enem['CAT_ENSINO'] != 0) &\n",
    "    (df_enem['CAT_ESCOLA'] != 1)\n",
    "]\n",
    "#Variaveis alvo\n",
    "variaveis_alvo = ['NUM_NOTA_MT', 'NUM_NOTA_LC', 'NUM_NOTA_CN', 'NUM_NOTA_CH', 'NUM_NOTA_REDACAO']\n",
    "\n",
    "# separar em treino e teste\n",
    "X = df_enem.drop(columns=variaveis_alvo)\n",
    "y = df_enem[variaveis_alvo]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste de tipo para MLflow -> Converter colunas inteiras para float\n",
    "X_train = X_train.astype({col: 'float' for col in X_train.select_dtypes('int').columns})\n",
    "X_test = X_test.astype({col: 'float' for col in X_test.select_dtypes('int').columns})\n",
    "\n",
    "# Obter colunas categ√≥ricas\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Criar Eval Set para valida√ß√£o cruzada (15% do conjunto de treino)\n",
    "# Apenas utilizado nos modelos fianais, BayesSearchCV n√£o utiliza Eval Set j√° possui validacao cruzada interna\n",
    "X_train_final, X_eval, y_train_final, y_eval = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52d014",
   "metadata": {},
   "source": [
    "Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95c695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30394\n",
      "[LightGBM] [Info] Number of data points in the train set: 478696, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 528.797023\n"
     ]
    }
   ],
   "source": [
    "# Treinar modelo LGBMRegressor Base\n",
    "modelo_lgbm = lgbm.LGBMRegressor(n_estimators=1000, \n",
    "                                 learning_rate=0.01, \n",
    "                                 random_state=42,\n",
    "                                 max_bin=4095,\n",
    "                                 force_row_wise=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "modelo_lgbm.fit(X_train_final, \n",
    "                y_train_final['NUM_NOTA_CH'], \n",
    "                eval_set=[(X_test, y_test['NUM_NOTA_CH'])], \n",
    "                eval_metric=['r2', 'rmse', 'mae'],\n",
    "                categorical_feature=categorical_features)\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20fbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred = modelo_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316e6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/11 13:17:24 INFO mlflow.tracking.fluent: Experiment with name 'Escolares CH 2023' does not exist. Creating a new experiment.\n",
      "2025/06/11 13:17:44 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Successfully registered model 'modelo_lgbm_base_escolares_2023'.\n",
      "2025/06/11 13:17:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_base_escolares_2023, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run overjoyed-turtle-87 at: http://127.0.0.1:9080/#/experiments/623589849857672017/runs/89bcdfd7e5e04d0f92d535887452118b\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/623589849857672017\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_base_escolares_2023\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'modelo_lgbm_base_escolares_2023'.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Escolares CH 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                 parametros={**modelo_lgbm.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                 X_train=X_train,\n",
    "                 y_train=y_train,\n",
    "                 y_test=y_test,\n",
    "                 y_pred=y_pred,\n",
    "                 variavel_alvo='NUM_NOTA_CH',\n",
    "                 modelo=modelo_lgbm,\n",
    "                 nome_modelo='modelo_lgbm_base_escolares_2023',\n",
    "                 descricao_modelo='Modelo LGBMRegressor base para dados escolares CH',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c6f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 58.3056\n",
      "RMSE (treino): 73.4808\n",
      "R2 (treino): 0.2425\n",
      "MAE (teste): 58.8803\n",
      "RMSE (teste): 74.1800\n",
      "R2 (teste): 0.2282\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred, \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213e27b4",
   "metadata": {},
   "source": [
    "Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e476ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lgbm_bayes = lgbm.LGBMRegressor(random_state=42,\n",
    "                                       max_bin=4095, \n",
    "                                       force_row_wise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d89975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o do espa√ßo de busca para otimiza√ß√£o bayesiana\n",
    "param_grid = {\n",
    "    'num_leaves': (5, 60),                         # N√∫mero de folhas na √°rvore de decis√£o\n",
    "    'max_depth': (60, 120),                        # Profundidade m√°xima da √°rvore\n",
    "    'learning_rate': (0.001, 0.01, 'log-uniform'), # Taxa de aprendizado\n",
    "    'n_estimators': (5000, 8000),                  # N√∫mero de √°rvores\n",
    "    'subsample': (0.1, 0.9),                       # Propor√ß√£o de amostras usadas em cada √°rvore\n",
    "    'colsample_bytree': (0.1, 0.9),                # Fra√ß√£o de colunas a serem usadas por √°rvore\n",
    "    'reg_alpha': (1e-3, 1.0, 'log-uniform'),       # Regulariza√ß√£o L1\n",
    "    'reg_lambda': (1e-7, 1e-2, 'log-uniform'),     # Regulariza√ß√£o L2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d82d1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar a busca Bayesiana usando BayesSearchCV\n",
    "\n",
    "# Criando o otimizador Bayesiano\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=modelo_lgbm_bayes,    # Modelo a ser otimizado\n",
    "    search_spaces=param_grid,       # Espa√ßo de busca definido acima\n",
    "    scoring='r2',                   # Crit√©rio de sele√ß√£o\n",
    "    n_iter=5,                       # N√∫mero de avalia√ß√µes do modelo\n",
    "    cv=5,                           # Valida√ß√£o cruzada\n",
    "    random_state=42,                # Semente para reprodutibilidade\n",
    "    n_jobs=-1,                      # Paraleliza√ß√£o total dos c√°lculos\n",
    "    verbose=1                       # 0 = sem mensagens, 1 = mensagens de progresso, 2 = mensagens detalhadas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58217271",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'eval_metric': ['r2', 'rmse', 'mae'],              # M√©tricas a serem avaliadas\n",
    "    'categorical_feature': categorical_features,       # Colunas categ√≥ricas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d2c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] Total Bins 30475\n",
      "[LightGBM] [Info] Number of data points in the train set: 563172, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 528.818375\n"
     ]
    }
   ],
   "source": [
    "# Executar a busca Bayesiana\n",
    "\n",
    "start_time = time.time()\n",
    "bayes_search.fit(X_train, y_train['NUM_NOTA_CH'], **fit_params)\n",
    "\n",
    "# Parar o cron√¥metro\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20062d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros: OrderedDict([('colsample_bytree', 0.4558660098409215), ('learning_rate', 0.008293207307063736), ('max_depth', 66), ('n_estimators', 6300), ('num_leaves', 15), ('reg_alpha', 0.02296127666011783), ('reg_lambda', 5.987427535052461e-07), ('subsample', 0.7012420250723972)])\n",
      "R2:  0.22851773701869255\n",
      "Tempo total de execu√ß√£o: 23330.66 segundos\n"
     ]
    }
   ],
   "source": [
    "# Melhores par√¢metros encontrados\n",
    "try:\n",
    "    melhores_parametros = bayes_search.best_params_\n",
    "    print(f\"Melhores par√¢metros: {melhores_parametros}\")\n",
    "    print(\"R2: \", bayes_search.best_score_)\n",
    "    print(f\"Tempo total de execu√ß√£o: {elapsed_time:.2f} segundos\")\n",
    "except:\n",
    "    melhores_parametros = {'colsample_bytree': 0.4558660098409215, 'learning_rate': 0.008293207307063736, 'max_depth': 66, 'n_estimators': 6300, 'num_leaves': 15, 'reg_alpha': 0.02296127666011783, 'reg_lambda': 5.987427535052461e-07, 'subsample': 0.7012420250723972}\n",
    "    print(f\"Erro ao obter melhores par√¢metros, usando valores calculados anteriormente:\\n {melhores_parametros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18551012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 30394\n",
      "[LightGBM] [Info] Number of data points in the train set: 478696, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score 528.797023\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4054]\tvalid_0's rmse: 74.1533\tvalid_0's l1: 58.8522\tvalid_0's l2: 5498.71\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.set_params(**melhores_parametros)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Treinamento do modelo com os melhores par√¢metros encontrados\n",
    "modelo_lgbm_bayes.fit(X_train_final, \n",
    "                      y_train_final['NUM_NOTA_CH'], \n",
    "                      eval_set=[(X_eval, y_eval['NUM_NOTA_CH'])], \n",
    "                      eval_metric=['r2', 'rmse', 'mae'],\n",
    "                      categorical_feature=categorical_features,\n",
    "                      callbacks=[early_stopping(stopping_rounds=200)])\n",
    "\n",
    "tempo_treino = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1b52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "y_pred_bayes = modelo_lgbm_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9da75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/11 19:55:37 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Successfully registered model 'modelo_lgbm_bayes_escolares_2023'.\n",
      "2025/06/11 19:55:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: modelo_lgbm_bayes_escolares_2023, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run invincible-hound-299 at: http://127.0.0.1:9080/#/experiments/623589849857672017/runs/4698a5dbdcff4d00aab1c92c993655dc\n",
      "üß™ View experiment at: http://127.0.0.1:9080/#/experiments/623589849857672017\n",
      "Modelo registrado com sucesso no MLflow: modelo_lgbm_bayes_escolares_2023\n",
      "Rastreamento do MLflow finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'modelo_lgbm_bayes_escolares_2023'.\n"
     ]
    }
   ],
   "source": [
    "nome_experimento = 'Escolares CH 2023'\n",
    "\n",
    "registrar_modelo(experimento=nome_experimento,\n",
    "                    modelo=modelo_lgbm_bayes,\n",
    "                    parametros={**modelo_lgbm_bayes.get_params(), \"amostra\": X_train.shape[0], \"tempo\": tempo_treino},\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    y_test=y_test,\n",
    "                    y_pred=y_pred_bayes,\n",
    "                    variavel_alvo='NUM_NOTA_CH',\n",
    "                    nome_modelo='modelo_lgbm_bayes_escolares_2023',\n",
    "                    descricao_modelo='Modelo LGBMRegressor otimizado com BayesSearchCV para dados escolares CH',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5d1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (treino): 58.3570\n",
      "RMSE (treino): 73.5440\n",
      "R2 (treino): 0.2412\n",
      "MAE (teste): 58.8581\n",
      "RMSE (teste): 74.1456\n",
      "R2 (teste): 0.2290\n"
     ]
    }
   ],
   "source": [
    "# Avalia√ß√£o grupo treino\n",
    "avaliar_modelo(y_train['NUM_NOTA_CH'], modelo_lgbm_bayes.predict(X_train), \"treino\")\n",
    "\n",
    "# Avalia√ß√£o grupo teste\n",
    "avaliar_modelo(y_test['NUM_NOTA_CH'], y_pred_bayes, \"teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9600a984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/modelo_lgbm_bayes_escolares.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar modelo como Pickle\n",
    "joblib.dump(modelo_lgbm_bayes, 'modelos/modelo_lgbm_bayes_escolares.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
